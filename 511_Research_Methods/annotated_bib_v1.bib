
@inproceedings{gui_adapting_2024,
	title = {Adapting {Frechet} {Audio} {Distance} for {Generative} {Music} {Evaluation}},
	doi = {10.1109/ICASSP48485.2024.10446663},
	booktitle = {{ICASSP} 2024 - 2024 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Gui, Azalea and Gamper, Hannes and Braun, Sebastian and Emmanouilidou, Dimitra},
	year = {2024},
	keywords = {Acoustics, Adaptation models, Correlation, Evaluation Metrics, Frechet Audio Distance, Generative model, Measurement, Music/Audio generation, Predictive models, Quality Assessment, Signal processing, Speech processing},
	pages = {1331--1335},
}

@misc{vinay_evaluating_2022,
	title = {Evaluating generative audio systems and their metrics},
	url = {https://arxiv.org/abs/2209.00130},
	author = {Vinay, Ashvala and Lerch, Alexander},
	year = {2022},
	note = {\_eprint: 2209.00130},
}

@article{elgammal_can_2017,
	title = {{CAN}: {Creative} {Adversarial} {Networks}, {Generating} "{Art}" by {Learning} {About} {Styles} and {Deviating} from {Style} {Norms}},
	volume = {abs/1706.07068},
	url = {http://arxiv.org/abs/1706.07068},
	journal = {CoRR},
	author = {Elgammal, Ahmed M. and Liu, Bingchen and Elhoseiny, Mohamed and Mazzone, Marian},
	year = {2017},
	note = {arXiv: 1706.07068},
}

@inproceedings{colton_creativity_2008,
	title = {Creativity {Versus} the {Perception} of {Creativity} in {Computational} {Systems}.},
	volume = {8},
	booktitle = {{AAAI} spring symposium: creative intelligent systems},
	publisher = {Palo Alto, CA},
	author = {Colton, Simon},
	year = {2008},
	pages = {7},
}

@misc{elgammal_quantifying_2015,
	title = {Quantifying {Creativity} in {Art} {Networks}},
	url = {https://arxiv.org/abs/1506.00711},
	author = {Elgammal, Ahmed and Saleh, Babak},
	year = {2015},
	note = {\_eprint: 1506.00711},
}

@article{kreuk_audiogen_2022,
	title = {Audiogen: {Textually} guided audio generation},
	journal = {arXiv preprint arXiv:2209.15352},
	author = {Kreuk, Felix and Synnaeve, Gabriel and Polyak, Adam and Singer, Uriel and DÃ©fossez, Alexandre and Copet, Jade and Parikh, Devi and Taigman, Yaniv and Adi, Yossi},
	year = {2022},
	file = {PDF:/Users/mej/Zotero/storage/6BRSRNL4/Kreuk et al. - 2022 - Audiogen Textually guided audio generation.pdf:application/pdf},
}

@article{van_den_oord_wavenet_2016,
	title = {Wavenet: {A} generative model for raw audio},
	volume = {12},
	journal = {arXiv preprint arXiv:1609.03499},
	author = {Van Den Oord, Aaron and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray and {others}},
	year = {2016},
	file = {PDF:/Users/mej/Zotero/storage/7JNDTSBL/Van Den Oord et al. - 2016 - Wavenet A generative model for raw audio.pdf:application/pdf},
}

@article{engel_ddsp_2020,
	title = {{DDSP}: {Differentiable} digital signal processing},
	journal = {arXiv preprint arXiv:2001.04643},
	author = {Engel, Jesse and Hantrakul, Lamtharn and Gu, Chenjie and Roberts, Adam},
	year = {2020},
	file = {PDF:/Users/mej/Zotero/storage/RZMX8HKS/Engel et al. - 2020 - DDSP Differentiable digital signal processing.pdf:application/pdf},
}

@article{garcia_vampnet_2023,
	title = {Vampnet: {Music} generation via masked acoustic token modeling},
	journal = {arXiv preprint arXiv:2307.04686},
	author = {Garcia, Hugo Flores and Seetharaman, Prem and Kumar, Rithesh and Pardo, Bryan},
	year = {2023},
	file = {PDF:/Users/mej/Zotero/storage/AZP4LHWJ/Garcia et al. - 2023 - Vampnet Music generation via masked acoustic token modeling.pdf:application/pdf},
}

@article{caillon_rave_2021,
	title = {{RAVE}: {A} variational autoencoder for fast and high-quality neural audio synthesis},
	journal = {arXiv preprint arXiv:2111.05011},
	author = {Caillon, Antoine and Esling, Philippe},
	year = {2021},
	file = {PDF:/Users/mej/Zotero/storage/T9H9U8ZE/Caillon and Esling - 2021 - RAVE A variational autoencoder for fast and high-quality neural audio synthesis.pdf:application/pdf},
}

@article{engel_gansynth_2019,
	title = {Gansynth: {Adversarial} neural audio synthesis},
	journal = {arXiv preprint arXiv:1902.08710},
	author = {Engel, Jesse and Agrawal, Kumar Krishna and Chen, Shuo and Gulrajani, Ishaan and Donahue, Chris and Roberts, Adam},
	year = {2019},
	file = {PDF:/Users/mej/Zotero/storage/5742YFXZ/Engel et al. - 2019 - Gansynth Adversarial neural audio synthesis.pdf:application/pdf},
}

@article{huang_improved_2018,
	title = {An {Improved} {Relative} {Self}-{Attention} {Mechanism} for {Transformer} with {Application} to {Music} {Generation}},
	volume = {abs/1809.04281},
	url = {http://arxiv.org/abs/1809.04281},
	journal = {CoRR},
	author = {Huang, Cheng-Zhi Anna and Vaswani, Ashish and Uszkoreit, Jakob and Shazeer, Noam and Hawthorne, Curtis and Dai, Andrew M. and Hoffman, Matthew D. and Eck, Douglas},
	year = {2018},
	note = {arXiv: 1809.04281},
	file = {PDF:/Users/mej/Zotero/storage/XQCQP2T2/Huang et al. - 2018 - An Improved Relative Self-Attention Mechanism for Transformer with Application to Music Generation.pdf:application/pdf},
}
