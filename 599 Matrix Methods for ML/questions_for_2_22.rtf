{\rtf1\ansi\ansicpg1252\cocoartf2759
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 What\'92s the reasoning behind creating a multinomial logistic regression as a benchmark?  Could we talk about multinomial logistic regression?  It\'92s basically just a single layer of neurons with [features] number of neurons, and for each input neuron there is a matrix of weights that gets multiplied by the input data points, bias added, so it\'92s a linear mapping of the input datapoints to a new set of datapoints?  It outputs a probability vector, so the vector\'92s extension in each dimension is the probability of the input data point belonging to the class indicated by that dimension?  So for the wine example, we have 11 features and 2 output dimensions.  The multinomial logistic regression takes the input data matrix (5,000x11), multiplies it by a weight matrix of 11x2 dimensions to get a 2-dimensional output vector?  And then that\'92s turned by softmax into a probability vector?  And then whatever loss function is used to get the distance, corrections are made via gradient descent, repeat?  Why is it called softmax regression?  How do I visualize the multi-dimensional classification curve?\
\
Could we talk about PCA?  Could we talk about ML kernel methods for transforming the data and when that\'92s a better solution than using a neural network?  Could we talk about other kinds of classification algorithms (random forest, SVM, K-nearest neighbors)?}